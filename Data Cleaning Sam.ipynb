{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "614c008a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import sys\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizerFast, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d61ba1",
   "metadata": {},
   "source": [
    "## Checking path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6fe079b5-ed1d-4da4-a824-36d14375ef2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/xykong/private/cse151b-2024-wi/AI_text_generator',\n",
       " '/opt/conda/lib/python39.zip',\n",
       " '/opt/conda/lib/python3.9',\n",
       " '/opt/conda/lib/python3.9/lib-dynload',\n",
       " '',\n",
       " '/home/xykong/.local/lib/python3.9/site-packages',\n",
       " '/opt/conda/lib/python3.9/site-packages',\n",
       " '/opt/conda/lib/python3.9/site-packages/IPython/extensions',\n",
       " '/home/xykong/.ipython']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142919b4",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4091463c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Can one of you guys download your facebook messenger data and upload the json file for this groupchat to the github repo? I can't download the 3 month one for some reason\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = open('data/CSE151B_groupchat_3mo.json')\n",
    "json_data = json.load(data_file)\n",
    "json_data['messages'][1]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b31e25b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_minute = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "275ac0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1664"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_data['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f001406-e8f8-45c9-9706-6557a8c05a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json_data['messages'][::-1] # reversing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ef9840e-d307-4444-ad6b-f24ffe8d54e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "junk_messages = ['reacted', 'X:1759 T:F\\\"ur Elise T:Bagatelle', 'Counter({50:', '--']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2088bb7",
   "metadata": {},
   "source": [
    "## Saving all lines (lines only, without names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e76a098d-56f0-4b5a-b057-15d6775359e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lines = []\n",
    "for i in range(len(json_data)):\n",
    "    if 'content' in json_data[i]:\n",
    "        msg = json_data[i]['content'].replace('√∞\\x9f\\x98\\x82', ' hahaha').encode('latin1').decode('utf-8').replace('\\n', ' ')\n",
    "        if ('reacted' not in msg and 'to your message' not in msg) and \\\n",
    "            '\\u200d‚ôÇÔ∏è' not in msg and '\\u200d‚ôÇÔ∏è' not in msg and \\\n",
    "            'https' not in msg and 'https' not in msg and \\\n",
    "            '.com' not in msg and '.com' not in msg and \\\n",
    "            np.all([junk not in msg for junk in junk_messages]):\n",
    "            all_lines.append(msg.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f6555432-5f3b-418d-9bc9-7e2abed17d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pa2!',\n",
       " 'thanks ester!',\n",
       " 'ester named the group cse 151b pa2.',\n",
       " 'what should our group name be üòé ester and i used transformers for pa1',\n",
       " 'lol anything works']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62613cfe-bb39-40de-bd51-82f3e360b7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing only lines to a text file\n",
    "\n",
    "with open('data/all_lines.txt', 'w+') as f:\n",
    "    for i in all_lines:\n",
    "        f.write(i)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7adb0f",
   "metadata": {},
   "source": [
    "## Creating tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f65e4220-c4c8-4348-85c7-fdaa13ad821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(text_fp, tokenizer_save_fp='tokenizer/', tokenizer_name='bert-base-uncased', max_vocab_size=32000):\n",
    "    lines = []\n",
    "    with open(text_fp) as file:\n",
    "        for line in file: \n",
    "            line = line.strip() \n",
    "            lines.append(line)\n",
    "            \n",
    "    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "    tokenizer = tokenizer.train_new_from_iterator(iter(lines), max_vocab_size)\n",
    "    print(\"Vocab size is: \", tokenizer.vocab_size)\n",
    "    tokenizer.save_pretrained(tokenizer_save_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ba96a7a-8ee5-409a-8f6e-74573067f33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Vocab size is:  3803\n"
     ]
    }
   ],
   "source": [
    "tokenizer_save_path = 'LSTM/tokenizer/'\n",
    "create_tokenizer('data/all_lines.txt', tokenizer_save_fp=tokenizer_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a504e159",
   "metadata": {},
   "source": [
    "## Creating prompt-response pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "846aedad",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_response = []\n",
    "for i in range(len(json_data)-1):\n",
    "    this_dict = {}\n",
    "    time_difference = json_data[i+1]['timestamp_ms'] - json_data[i]['timestamp_ms']\n",
    "    \n",
    "    #Keeps responses within 2minutes of previous message, removes photos\n",
    "    if json_data[i]['sender_name'] != json_data[i+1]['sender_name'] and \\\n",
    "        time_difference <= one_minute*2 and 'content' in json_data[i] and \\\n",
    "        'content' in json_data[i+1]:\n",
    "        \n",
    "        this_dict['prompt'] = json_data[i]['content'].replace('√∞\\x9f\\x98\\x82', ' hahaha').encode('latin1').decode('utf-8').replace('\\n', ' ').strip().lower()\n",
    "        this_dict['response'] = json_data[i+1]['content'].replace('√∞\\x9f\\x98\\x82', ' hahaha').encode('latin1').decode('utf-8').replace('\\n', ' ').strip().lower()\n",
    "        this_dict['user'] = json_data[i+1]['sender_name']\n",
    "        \n",
    "        \n",
    "        #removes reactions and links\n",
    "        if not(('reacted' in this_dict['prompt'] and 'to your message' in this_dict['prompt']) or \\\n",
    "        ('reacted' in this_dict['response'] and 'to your message' in this_dict['response'])) and \\\n",
    "        '\\u200d‚ôÇÔ∏è' not in this_dict['response'] and '\\u200d‚ôÇÔ∏è' not in this_dict['prompt'] and \\\n",
    "        'https' not in this_dict['response'] and 'https' not in this_dict['prompt'] and \\\n",
    "        '.com' not in this_dict['response'] and '.com' not in this_dict['prompt']:\n",
    "            prompt_response.append(this_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66cde4d-667b-4097-8ea3-2b4d1226e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_response[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14935398",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prompt_response.jsonl', 'w') as json_file:\n",
    "    for entry in prompt_response:\n",
    "        json.dump(entry, json_file)\n",
    "        json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0d876a",
   "metadata": {},
   "source": [
    "## Creating train, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "28de5765-8dde-47b6-880d-3b904a219538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_val_test(data, cutoff_percentage=0.8, test_count=10):\n",
    "    random.shuffle(data) \n",
    "    n = len(data)\n",
    "    train_cutoff = int(n*cutoff_percentage)\n",
    "    train_data = data[:train_cutoff]\n",
    "    val_data = data[train_cutoff:-test_count]\n",
    "    test_data = data[-test_count:]\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1291bd26-6f81-4c27-b4d6-764893d315d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_lst = []\n",
    "with open('data/prompt_response.jsonl', 'r') as json_file:\n",
    "    for row in json_file:\n",
    "        content = json.loads(row)\n",
    "        sentence_lst.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "44701602-5db6-441f-bcc5-069fab23a608",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = generate_train_val_test(sentence_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cc5fef06-7aa8-488e-aba6-ee6bdf2947cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 91, 10)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1a601a2f-592c-4bcf-8dc3-b6f0e202dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def create_data_loader(data, batch_size=10, loop=True, shuffle=True):\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "                data,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=shuffle)\n",
    "\n",
    "    if loop:\n",
    "        return infinite_loader(data_loader)\n",
    "    else:\n",
    "        # print(data_loader)\n",
    "        return iter(data_loader)\n",
    "\n",
    "def infinite_loader(data_loader):\n",
    "    while True:\n",
    "        yield from data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "09b7de99-e399-4fc7-93e4-c534c47745a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = create_data_loader(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "39eb7ad8-f3b4-47b2-9c9f-6bd07f46acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = next(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e9485089-eb20-47a5-ae6c-f3da3f4e3ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_batch['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad8e099-65a0-489d-a810-2617743feebb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
